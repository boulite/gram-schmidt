\documentclass{article}

\usepackage{amsmath, amsthm}
\usepackage{amssymb}
\usepackage[margin=1in]{geometry}
\usepackage{lastpage} % for the number of the last page in the document
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\lhead{Michael Akintunde}
\chead{CID: 00828840}
\rhead{M2AA3 Project 1}
\lfoot{\today}
\rfoot{Page \thepage\ of \pageref{LastPage}}

\newcommand{\mgs}[1] {\underline{\overline{#1}}}
\newcommand{\cgs}[1] {\underline{#1}}
\newcommand{\mgzz}[2] {\ensuremath{\underline{\overline{#1}}}_{#2}}
\newcommand{\mgz}[3] {\ensuremath{\underline{\overline{#1}}}_{#2}^{(#3)}}
\newcommand{\cgz}[2] {\ensuremath{\underline{#1}}_{#2}}
\newcommand{\brackit}[2] {\ensuremath{\left\langle #1,\,#2 \right\rangle}}

\newtheorem{theorem}{Lemma}

\begin{document}
\title{M2AA3 - Project 1}
\author{Michael Akintunde - CID: 00828840}

\maketitle

\begin{enumerate}
	\item 
	\begin{theorem}
	The Modified Gram-Schmidt Algorithm (mgs) outputs vectors $\mgs{q}_1$, $\mgs{q}_2$, $\ldots$ , $\mgs{q}_n \in \mathbb{R}^n$ such that $$\mgs{q}_i \equiv \cgs{q}_i, \qquad i = 1 \rightarrow n.$$
	\end{theorem}
	\begin{proof}
	$\left\{ \cgs{a}_i \right\}_{i=1}^n \text{ is linearly independent.}$
	\begin{align*}
		\implies \cgs{a}_i &\neq \underline{0} , \qquad i = 1 \rightarrow n. \\
		\implies \mgs{v}_i^{(1)} &= \cgs{a}_i \neq \underline{0} \\
		\implies \mgs{v}_1^{(1)} &= \cgs{a}_1 \neq \underline{0} \\
		\implies \|\mgs{v}_1^{(1)}\| &\neq 0. \\
		\mgs{q}_1 &= \dfrac{\mgs{v}_1^{(1)}}{\|\mgs{v}_1^{(1)}\|} \\
		\implies \|\mgs{q}_1\| &= \left( \langle \mgs{q}_1 , \mgs{q}_1 \rangle \right)^{1/2}	\\
		&= \left( \left\langle \dfrac{\mgs{v}_1^{(1)}}{\|\mgs{v}_1^{(1)}\|} , \dfrac{\mgs{v}_1^{(1)}}{\|\mgs{v}_1^{(1)}\|} \right\rangle \right)^{1/2} \\
		&= \left( \dfrac{1}{\|\mgs{v}_1^{(1)}\|^2} \left\langle \mgs{v}_1^{(1)} , \mgs{v}_1^{(1)} \right\rangle \right)^{1/2} \\
		&= \left( \dfrac{1}{\|\mgs{v}_1^{(1)}\|^2} \cdot  \|\mgs{v}_1^{(1)}\|^2 \right)^{1/2} = 1 \\
		\implies \mgs{q}_1 \text{ is orthonormal}.\\
		\mgs{v}_2^{(2)} &= \mgs{v}_2^{(1)} - \langle \mgs{v}_2^{(1)}, \mgs{q}_1 \rangle \mgs{q}_1. \\
		\langle \mgs{v}_2^{(2)}, \mgs{q}_1 \rangle 
		&= \langle \mgs{v}_2^{(1)} - \langle \mgs{v}_2^{(1)}, \mgs{q}_1 \rangle \mgs{q}_1, \mgs{q}_1 \rangle \\
		&= \langle \mgs{v}_2^{(1)}, \mgs{q}_1 \rangle - \langle \mgs{v}_2^{(1)}, \mgs{q}_1 \rangle \langle \mgs{q}_1, \mgs{q}_1 \rangle \\
		&= \langle \mgs{v}_2^{(1)}, \mgs{q}_1 \rangle - \langle \mgs{v}_2^{(1)}, \mgs{q}_1 \rangle  \|\mgs{q}_1\|^2 \\
		&= \langle \mgs{v}_2^{(1)}, \mgs{q}_1 \rangle - \langle \mgs{v}_2^{(1)}, \mgs{q}_1 \rangle \cdot 1 \\
		&= 0. \\
		\therefore \mgs{v}_2^{(2)} \text{ is orthogonal to } \mgs{q}_1.
	\end{align*}
	Form $\mgs{q}_2 = \mgs{v}_2^{(2)} / \| \mgs{v}_2^{(2)} \|$. We need to check that $\| \mgs{v}_2^{(2)} \| \neq 0$. \\
	If $\| \mgs{v}_2^{(2)}\| = 0 $, 
	\begin{align*}
	\mgs{v}_2^{(1)} &= \langle \mgs{v}_2^{(1)}, \mgs{q}_1 \rangle \mgs{q}_1 \\
	\implies &\mgs{v}_2^{(1)} \text{ is a multiple of } \mgs{q}_1 \\
	\implies &\cgs{a}_2 \text{ is a multiple of } \mgs{q}_1 \\ 
	\implies &\cgs{a}_2 \text{ is a multiple of } \cgs{a}_1 \\ 
	\end{align*}
	Which leads to a contradiction to $\left\{ \cgs{a}_i \right\}_{i=1}^n \text{ being linearly independent.}$
	
	\textbf{Inductive case:}
	Assume the following inductive hypothesis: 
	\begin{equation} \label{eq:indhyp}
		\mgz{v}{j}{i} = \cgz{a}{j} - \sum\limits_{k=1}^{i-1} \brackit{\cgz{a}{j}}{\mgzz{q}{k}}\mgzz{q}{k}, \qquad \text{where } \{ \mgzz{q}{k} \}_{k=1}^{i-1} \in \mathbb{R}^m \text{ are orthonormal.}
	\end{equation}

	Fix $j$. With $i = p + 1$, we want to show that:
	\begin{align*} \label{eq:indcase}
		\mgz{v}{j}{p+1} &= \cgz{a}{j} - \sum\limits_{k=1}^{(p+1)-1} \brackit{\cgz{a}{j}}{\mgzz{q}{k}}\mgzz{q}{k} \\
		&= \cgz{a}{j} - \sum\limits_{k=1}^{p} \brackit{\cgz{a}{j}}{\mgzz{q}{k}}\mgzz{q}{k}
	\end{align*}
	
	Now, by the definition of the \textbf{mgs} we have:
	\begin{align*}
	\mgz{v}{j}{p+1} &= \mgz{v}{j}{p} - \brackit{\mgz{v}{j}{p}}{\mgzz{q}{p}} \\
	&= \cgz{a}{j} - \sum\limits_{k=1}^{p-1} \brackit{\cgz{a}{j}}{\mgzz{q}{k}}\mgzz{q}{k} \qquad \text{By (\ref{eq:indhyp})} \\
	&- \brackit{ \cgz{a}{j} - \sum\limits_{k=1}^{p-1} \brackit{\cgz{a}{j}}{\mgzz{q}{k}}\mgzz{q}{k} }{ \mgzz{q}{p} } \mgzz{q}{p} \\
	&= \cgz{a}{j} - \sum\limits_{k=1}^{p-1} \brackit{\cgz{a}{j}}{\mgzz{q}{k}}\mgzz{q}{k} - \left( \brackit{ \cgz{a}{j} }{ \mgzz{q}{p} } - \sum\limits_{k=1}^{p-1} \brackit{ \cgz{a}{j} }{ \mgzz{q}{k} } \brackit{ \mgzz{q}{k} }{ \mgzz{q}{p} } \right) \mgzz{q}{p} \\
	&= \cgz{a}{j} - \sum\limits_{k=1}^{p-1} \brackit{\cgz{a}{j}}{\mgzz{q}{k}}\mgzz{q}{k} - \brackit{ \cgz{a}{j} }{ \mgzz{q}{p} } \mgzz{q}{p}, \qquad \text{since } \brackit{ \mgzz{q}{k} }{ \mgzz{q}{p} } = 0 \text{ for } k = q \rightarrow p-1. \\
	&= \cgz{a}{j} - \sum\limits_{k=1}^{p} \brackit{\cgz{a}{j}}{\mgzz{q}{k}}\mgzz{q}{k} \\
	\end{align*}
	Which, by induction, is what was required. Since $i = p + 1$,
	\begin{align*}
	\mgz{v}{j}{p+1} &= 
	\cgz{a}{j} - \sum\limits_{k=1}^{p} \brackit{\cgz{a}{j}}{\mgzz{q}{k}}\mgzz{q}{k} \\
	&=  \cgz{a}{j} - \sum\limits_{k=1}^{i-1} \brackit{\cgz{a}{j}}{\mgzz{q}{k}}\mgzz{q}{k}\\
	&= \cgz{v}{j}.
	\end{align*}
	Therefore, we can construct $\mgzz{q}{i} = {\mgz{v}{i}{i}}/{\| \mgz{v}{i}{i} \|} = {\cgz{v}{i}}/{\| \cgz{v}{i} \|} = \cgz{q}{i}$
	\end{proof}
	\item Computer listings of code:
	\begin{enumerate}
		\item \textbf{Classical Gram-Schmidt Algorithm (cgs)}:
		\begin{verbatim}
function[result] = gran_schmidt(varargin)
    % Convert input arguments into A.
    A_raw = cellfun(@transpose, varargin, 'UniformOutput', false);  
    A = cell2mat(A_raw);
    
    % Initialise the first column vector of V to be the first column 
    % vector of A.
    V(:,1) = A(:, 1);
    
    % Normalise the first column vector of V to become the first column
    % vector of Q.
    Q(:,1) = V(:,1) / norm(V(:,1));
    
    % Initialise the rest of the columns of the Q matrix.
    for i=2:nargin,
        V(:,i) = A(:, i) - sum(A, Q, i);
        Q(:,i) = V(:, i) / norm(V(:,i));
    end
    result = (Q' * Q) - eye(nargin);
end

function[result] = sum(A, Q, i)
    R = zeros(size(A, 1), 1);
    for j=1:i-1,
        R = R + dot(A(:,i), Q(:,j)) * Q(:,j);
    end    
    result = R;
end
		\end{verbatim}
		\item \textbf{Modified Gram-Schmidt Algorithm (mgs)}:
		\begin{verbatim}
function[result] = mod_gram_schmidt(varargin)
    % Convert input arguments into A.
    A_raw = cellfun(@transpose, varargin, 'UniformOutput', false);  
    A = cell2mat(A_raw);
    
    % Initialise the first 'page' of V matrices.
    for i=1:nargin,
        V(:,i,1) = A(:,i);
    end
    
    % Initialise the first column of Q.
    Q(:,1) = V(:,1,1) / norm(V(:,1,1));
    
    % Initialise the rest of the column vectors of Q.
    for i=2:nargin,
        for j=i:nargin,
            V(:,j,i) = V(:,j,i-1) - dot(V(:,j,i-1), Q(:,i-1)) * Q(:,i-1);
        end
        Q(:,i) = V(:,i,i) / norm(V(:,i,i));
    end    
    result = Q;
end

		\end{verbatim}
	\end{enumerate}
\end{enumerate}

\end{document}
